{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import scipy\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = scipy.ndimage.imread(\"images/me.jpg\",mode=None).astype(np.float32)/255.0\n",
    "style = scipy.ndimage.imread(\"images/style.png\",mode=\"RGB\").astype(np.float32)/255.0\n",
    "\n",
    "shape = (int(round(style.shape[0]/1.5,0)),int(round(style.shape[1]/1.5,0)),3)\n",
    "\n",
    "\n",
    "content_resized = skimage.transform.resize(content,shape).astype(np.float32)\n",
    "style_resized = skimage.transform.resize(style,shape).astype(np.float32)\n",
    "\n",
    "rn_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n",
    "preproc = lambda x: (x - rn_mean)[:, :, ::-1]\n",
    "deproc = lambda x: np.clip(x[:, :, ::-1] + rn_mean, 0, 255)\n",
    "\n",
    "content_resized = preproc(content_resized)\n",
    "style_resized = preproc(style_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(content_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(style_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in model.layers:\n",
    "    print(a.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layer = model.get_layer(\"block5_conv1\").output\n",
    "style_layer = model.get_layer(\"block1_conv1\").output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippet below comes from the [fast.ai course](http://course.fast.ai/lessons/lesson8.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, f, shp): self.f, self.shp = f, shp\n",
    "        \n",
    "    def loss(self, x):\n",
    "        loss_, self.grad_values = self.f([x.reshape(self.shp)])\n",
    "        return loss_.astype(np.float64)\n",
    "\n",
    "    def grads(self, x): return self.grad_values.flatten().astype(np.float64)\n",
    "\n",
    "def generate_function(model,layer,input): \n",
    "    input = np.expand_dims(input,0)\n",
    "    local_model = keras.Model(model.input, layer)\n",
    "    local_targ = K.variable(local_model.predict(input))\n",
    "    loss = K.sum(keras.metrics.mse(layer, local_targ))\n",
    "    grads = K.gradients(loss, model.input)\n",
    "    fn = K.function([model.input], [loss]+grads)\n",
    "    evaluator = Evaluator(fn, input.shape)\n",
    "    return fn,evaluator\n",
    "\n",
    "def solve_image(eval_obj, niter, x,name):\n",
    "    for i in range(niter):\n",
    "        x, min_val, info = scipy.optimize.fmin_l_bfgs_b(eval_obj.loss, x.flatten(),\n",
    "                                         fprime=eval_obj.grads, maxfun=20)\n",
    "        x = np.clip(x, -127,127)\n",
    "        print('Current loss value:', min_val)\n",
    "        imageio.imwrite(\"results/{}_at_iteration_{}.png\".format(name,i), deproc(x.reshape(shape)))\n",
    "    return x\n",
    "\n",
    "def gram_matrix(x):\n",
    "    # We want each row to be a channel, and the columns to be flattened x,y locations\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    # The dot product of this with its transpose shows the correlation \n",
    "    # between each pair of channels\n",
    "    the_dot = K.dot(features, K.transpose(features))\n",
    "    num_elems = x.get_shape().num_elements()\n",
    "    return the_dot / num_elems\n",
    "def style_loss(x, targ): return keras.metrics.mse(gram_matrix(x), gram_matrix(targ))\n",
    "\n",
    "\n",
    "content_function,content_evaluator = generate_function(model,content_layer,content_resized)\n",
    "style_function,style_evaluator = generate_function(model,style_layer,style_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(-2.5, 2.5, [1]+list(shape))/100\n",
    "#plt.imshow(x[0]);\n",
    "iterations=100\n",
    "x = solve_image(content_evaluator, iterations, x,\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_function(model,content_layer,style_layer,input_content,input_style): \n",
    "    input_content = np.expand_dims(input_content,0)\n",
    "    input_style = np.expand_dims(input_style,0)\n",
    "    \n",
    "    content_model = keras.Model(model.input, [content_layer])\n",
    "    style_model = keras.Model(model.input, [style_layer])\n",
    "    content_targ = K.variable(content_model.predict(input_content))\n",
    "    style_targ = K.variable(style_model.predict(input_style))\n",
    "    \n",
    "    content_loss = K.sum(keras.metrics.mse(content_layer, content_targ))\n",
    "    _style_loss = style_loss(style_layer[0],style_targ[0])\n",
    "\n",
    "    loss = content_loss + _style_loss\n",
    "    \n",
    "    grads = K.gradients(loss, model.input)\n",
    "    fn = K.function(model.input, [loss]+grads)\n",
    "    evaluator = Evaluator(fn, input_content.shape)\n",
    "    return fn,evaluator\n",
    "transfer_function,transfer_evaluator = generate_final_function(model,content_layer,style_layer,content_resized,style_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = content_resized.copy()\n",
    "x = solve_image(transfer_evaluator, 10, x,\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai_snippets]",
   "language": "python",
   "name": "conda-env-ai_snippets-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
