{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import scipy\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import imageio\n",
    "import vgg16_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brain/miniconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  if __name__ == '__main__':\n",
      "/home/brain/miniconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/brain/miniconda3/envs/fastai/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/brain/miniconda3/envs/fastai/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "content = scipy.ndimage.imread(\"images/me.jpg\",mode=None).astype(np.float32)/255.0\n",
    "style = scipy.ndimage.imread(\"images/style.png\",mode=\"RGB\").astype(np.float32)/255.0\n",
    "\n",
    "shape = (int(round(style.shape[0]/1.5,0)),int(round(style.shape[1]/1.5,0)),3)\n",
    "\n",
    "\n",
    "content_resized = skimage.transform.resize(content,shape).astype(np.float32)\n",
    "style_resized = skimage.transform.resize(style,shape).astype(np.float32)\n",
    "\n",
    "rn_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n",
    "preproc = lambda x: (x - rn_mean)[:, :, ::-1]\n",
    "deproc = lambda x: np.clip(x[:, :, ::-1] + rn_mean, 0, 255)\n",
    "\n",
    "content_resized = preproc(content_resized)\n",
    "style_resized = preproc(style_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(content_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(style_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16_avg.VGG16_Avg(include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "block1_conv1\n",
      "block1_conv2\n",
      "block1_pool\n",
      "block2_conv1\n",
      "block2_conv2\n",
      "block2_pool\n",
      "block3_conv1\n",
      "block3_conv2\n",
      "block3_conv3\n",
      "block3_pool\n",
      "block4_conv1\n",
      "block4_conv2\n",
      "block4_conv3\n",
      "block4_pool\n",
      "block5_conv1\n",
      "block5_conv2\n",
      "block5_conv3\n",
      "block5_pool\n"
     ]
    }
   ],
   "source": [
    "for a in model.layers:\n",
    "    print(a.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layer = model.get_layer(\"block5_conv1\").output\n",
    "style_layer = model.get_layer(\"block1_conv1\").output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippet below comes from the [fast.ai course](http://course.fast.ai/lessons/lesson8.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras' has no attribute 'Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f2cba32b6939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mcontent_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontent_evaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontent_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontent_resized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mstyle_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstyle_evaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstyle_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstyle_resized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f2cba32b6939>\u001b[0m in \u001b[0;36mgenerate_function\u001b[0;34m(model, layer, input)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlocal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlocal_targ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_targ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras' has no attribute 'Model'"
     ]
    }
   ],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, f, shp): self.f, self.shp = f, shp\n",
    "        \n",
    "    def loss(self, x):\n",
    "        loss_, self.grad_values = self.f([x.reshape(self.shp)])\n",
    "        return loss_.astype(np.float64)\n",
    "\n",
    "    def grads(self, x): return self.grad_values.flatten().astype(np.float64)\n",
    "\n",
    "def generate_function(model,layer,input): \n",
    "    input = np.expand_dims(input,0)\n",
    "    local_model = keras.model.Model(model.input, layer)\n",
    "    local_targ = K.variable(local_model.predict(input))\n",
    "    loss = K.sum(keras.metrics.mse(layer, local_targ))\n",
    "    grads = K.gradients(loss, model.input)\n",
    "    fn = K.function([model.input], [loss]+grads)\n",
    "    evaluator = Evaluator(fn, input.shape)\n",
    "    return fn,evaluator\n",
    "\n",
    "def solve_image(eval_obj, niter, x,name):\n",
    "    for i in range(niter):\n",
    "        x, min_val, info = scipy.optimize.fmin_l_bfgs_b(eval_obj.loss, x.flatten(),\n",
    "                                         fprime=eval_obj.grads, maxfun=20)\n",
    "        x = np.clip(x, -127,127)\n",
    "        print('Current loss value:', min_val)\n",
    "        imageio.imwrite(\"results/{}_at_iteration_{}.png\".format(name,i), deproc(x.reshape(shape)))\n",
    "    return x\n",
    "\n",
    "def gram_matrix(x):\n",
    "    # We want each row to be a channel, and the columns to be flattened x,y locations\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    # The dot product of this with its transpose shows the correlation \n",
    "    # between each pair of channels\n",
    "    the_dot = K.dot(features, K.transpose(features))\n",
    "    num_elems = x.get_shape().num_elements()\n",
    "    return the_dot / num_elems\n",
    "def style_loss(x, targ): return keras.metrics.mse(gram_matrix(x), gram_matrix(targ))\n",
    "\n",
    "\n",
    "content_function,content_evaluator = generate_function(model,content_layer,content_resized)\n",
    "style_function,style_evaluator = generate_function(model,style_layer,style_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(-2.5, 2.5, [1]+list(shape))/100\n",
    "#plt.imshow(x[0]);\n",
    "iterations=100\n",
    "x = solve_image(content_evaluator, iterations, x,\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_function(model,content_layer,style_layer,input_content,input_style): \n",
    "    input_content = np.expand_dims(input_content,0)\n",
    "    input_style = np.expand_dims(input_style,0)\n",
    "    \n",
    "    content_model = keras.Model(model.input, [content_layer])\n",
    "    style_model = keras.Model(model.input, [style_layer])\n",
    "    content_targ = K.variable(content_model.predict(input_content))\n",
    "    style_targ = K.variable(style_model.predict(input_style))\n",
    "    \n",
    "    content_loss = K.sum(keras.metrics.mse(content_layer, content_targ))\n",
    "    _style_loss = style_loss(style_layer[0],style_targ[0])\n",
    "\n",
    "    loss = content_loss + _style_loss\n",
    "    \n",
    "    grads = K.gradients(loss, model.input)\n",
    "    fn = K.function(model.input, [loss]+grads)\n",
    "    evaluator = Evaluator(fn, input_content.shape)\n",
    "    return fn,evaluator\n",
    "transfer_function,transfer_evaluator = generate_final_function(model,content_layer,style_layer,content_resized,style_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = content_resized.copy()\n",
    "x = solve_image(transfer_evaluator, 10, x,\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
